# Legal-Brief-Work Introduction
This repository is for developing a framework for legal briefs or case brief. A case brief is a dissection of a judicial opinion -- it contains a written summary of the basic components of that decision. Case briefing helps you acquire the skills of case analysis and legal reasoning. Briefing a case helps you understand it.  

Case briefing aids your memory. Briefs help you remember the cases you read (1) for class discussion, (2) for end-of-semester review for final examinations, and (3) for writing and analyzing legal problems. 

**CaseBriefs** folder contains sample case briefs for indian cases. Case Judgements for each case briefs are stored in **CaseJudgements** folder.

We have used OpenNyAi based BUILD Model to create the Rhetorical Roles (RR). You can find the details about the Rhetorical Role Baseline at the [Git Hub link](https://github.com/Legal-NLP-EkStep/rhetorical-role-baseline). 

Once, we get the RRs, we can now process them further for creating a Case Brief.

# System Overview

This work is build on top of [BUILDNyAI](https://legal-nlp-ekstep.github.io/Competitions/Rhetorical-Role/) model and [OpenNyAI NLP Pipeline](https://github.com/OpenNyAI/Opennyai). The OpenNyAI NLP Pipeline takes a legal Judgement and Produces three types of outputs with the help of three pre-trained models, namely - summarizer, NER and Rhetorical-Roles. 

You can also get all the three types of data (Summary, Name Entities, Rhetorical Roles) using this [WebAPP](https://summarizer-fer6v2lowq-uc.a.run.app/) provided by OpenNyAI. However, copying each rhetorical role is a cumbersome and highly inefficient task. So, we need to install the NLP Pipeline on our local system and then download the models output, in our case rhetorical roles, in JSON format (Sample JSON format for some Legal Judgement is available [here](https://github.com/suahmed31/Legal-Brief-Work/tree/main/JSON-Files)).

The technical issue with the JSON format in this case is its readability and thereby its analysis. The JSON format of legal text is a complex architecture as mentioned in its [description](https://github.com/Legal-NLP-EkStep/rhetorical-role-baseline). So, we have convert the same in to more efficient format and we choose it to be Comma Separated Values (CSV) format (Sample CSV format for some Legal Judgement is available [here](https://github.com/suahmed31/Legal-Brief-Work/tree/main/CSV)).

# Legal Brief Work

We extracted the following Rhetorical Roles from the CSV file that are needed for our Legal Brief Work:

1. Issues
2. Facts
3. Arguments
4. Holdings
5. Analysis

As, legal brief is a very important document all the content as generated by the model cannot be fed into the system that generates the brief. So, we created a **Rhetorical Roles Relatedness (RRR) Module**. The finds out the relative relatedness (or similarity) between the various roles. It can check which facts are in-line with the legal issue and drops those facts that do not have a semantic similarity with the legal issue. In this way a more concise and efficient factual summary is created. 

The following heatmap shows a sample of this relatedness between issue (01) and various facts (08) for a sample case.

![image](https://github.com/suahmed31/Legal-Brief-Work/blob/main/imgs/Issue-Facts-Heatmap.png)

If we analyze this heatmap, we can clearly see that **fact-6** (7.3%)and **fact-7** (8.6%) has the least relatedness with the issue compared with all the other facts. In forming the factual summary we will drop those facts which has similarity scores less that 10%. So, created a **factual statement/ fact summary** (ordered list) consisting of facts based on the relatedness of facts with the legal issue. The more related a fact is with the issue it is on the top of the summary.

Next, we checked the relatedness between various facts and arguments (both petitioner and respondent). In our case their were 09 Petitioner Arguments and 02 Respondent Arguments). The below mentioned image shows a comparative summary of the relatedness between various facts and arguments of the judgement.

![ComparisonSummary-Facts-Arguments](https://github.com/suahmed31/Legal-Brief-Work/blob/main/imgs/ComparisonSummary-Facts-Arguments.png)

Based on the similarity values, we had created the created an **argument summary**. After Facts, Issues, and Arguments, we need to analyze the Analysis/Reasoning of the Judgement. The Analysis Annotation in the Rhetorical Role is a super-set of Analysis, Statute, Precedent Relied, Precedent Not Relied, Ratio of the decision. So, we combined all the statements pertating to these roles in one single document and compared the Ratio i.e, the reason for the decision or judgement, with this single document. If the Ratio is correct, they must have certain similarity with this analysis document. The heatmap below shows the similarity of the ratios of the judgement and the analysis document and confirms its similarity. In case, so ratio do not match we can drop them as well while creating the summary.

![Ratio-Analysis](https://github.com/suahmed31/Legal-Brief-Work/blob/main/imgs/analysis-ratio-Heatmap.png)




